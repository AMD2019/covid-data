{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Facebook movement range maps, Google mobility data, and Oxford policy data for Nepal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Work done by Nepal Poverty Team, The World Bank_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources:\n",
    "1. [Google Community Mobility Reports](https://www.google.com/covid19/mobility/)\n",
    "2. [The Oxford COVID-19 Government Response Tracker](https://www.bsg.ox.ac.uk/research/research-projects/coronavirus-government-response-tracker) \n",
    "3. [Facebook Movement Range Maps](https://data.humdata.org/dataset/movement-range-maps) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used Python 3 and produced the Python 3 Jupyter notebook showing data cleaning and merging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running of this notebook requires Jupyter software system. Either Jupyter notebook or Jupyter lab can be installed on the system. In addition, two additional Python packages -- pycountry and pandas -- are required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter Software Installation\n",
    "https://jupyter.org/install\n",
    "\n",
    "### pandas Package Installation\n",
    "https://pandas.pydata.org/pandas-docs/stable/getting_started/install.html\n",
    "\n",
    "### GeoPandas Package Installation\n",
    "https://pypi.org/project/geopandas/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all the dependencies are installed the notebook can be imported to the Jupyter software and run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "import geopandas as gp\n",
    "\n",
    "from rasterstats import zonal_stats, gen_zonal_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch data, some from web URLs and some from downloaded local files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/regmi/envs/gis/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google mobility data fetched.\n",
      "OxCGRT data fetched.\n"
     ]
    }
   ],
   "source": [
    "# Tab delimited Facebook data, downloaded from the URL (https://data.humdata.org/dataset/movement-range-maps)\n",
    "fb_data = pd.read_csv('movement-range-2020-07-10.csv', sep='\\t')\n",
    "\n",
    "# Google mobility data, fetching from the web URL\n",
    "google_url = \"https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv\"\n",
    "google_data = pd.read_csv(google_url)\n",
    "print(\"Google mobility data fetched.\")\n",
    "\n",
    "# Oxford policy data, fetching from the web URL\n",
    "oxford_url = 'https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/OxCGRT_latest.csv'\n",
    "oxford_data = pd.read_csv(oxford_url)\n",
    "print(\"OxCGRT data fetched.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning of the data and zone names assertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the data to Nepal for all the data sources\n",
    "google_data = google_data[google_data['country_region_code'] == 'NP']\n",
    "oxford_data = oxford_data[oxford_data['CountryCode'] == 'NPL']\n",
    "fb_data = fb_data[fb_data['country'] == 'NPL']\n",
    "\n",
    "# bring the date to uniform format\n",
    "oxford_data['Date'] = oxford_data['Date'].apply(lambda x: str(x)).apply(lambda x: x[:4] + '-' + x[4:6] + '-' + x[6:])\n",
    "\n",
    "# the zone spelling for Dhaulagiri is wrong, so correcting it\n",
    "fb_data['polygon_name'] = fb_data['polygon_name'].replace(to_replace='Dhaualagiri', value='Dhaulagiri', regex=True)\n",
    "\n",
    "# assert if all the zone names are same between fb_data and shapefile\n",
    "assert set(fb_data['polygon_name'].unique()) - set(zone_popn.keys()) == set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepend the column names by `GCMR_`, `FB_` and `OXCGRT_` for Google mobility data, Facebook data and Oxford policy tracker data respectively. This helps us to distinguish the source of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCMR for Google Community Mobility Report\n",
    "google_data.columns = ['GCMR_' + i for i in google_data.columns]\n",
    "\n",
    "# FB for Our World in Development\n",
    "fb_data.columns = ['FB_' + i for i in fb_data.columns]\n",
    "\n",
    "# OXCGRT for Oxford COVID-19 Government Response Tracker\n",
    "oxford_data.columns = ['OXCGRT_' + i for i in oxford_data.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using rasterstats to calculate the zonal population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the zones shapefile\n",
    "adm_2 = gp.read_file('../GIS Data/Old/admin_2.shp')\n",
    "\n",
    "# run the zonal stats with \"sum\" stats\n",
    "stats = zonal_stats(adm_2, 'population_npl_2018-10-01.tif', all_touched=True, stats=['sum'], geojson_out=True)\n",
    "\n",
    "# get the zonal population and total population\n",
    "zone_popn = dict((stat['properties']['ZONE_NAME'], stat['properties']['sum']) for stat in stats)\n",
    "total_popn = sum(zone_popn.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate population weighted variables\n",
    "# first_var_dict => dictionary consisting population weighted all_day_bing_tiles_visited_relative_change value for each date (key)\n",
    "# second_var_dict => dictionary consisting population weighted all_day_ratio_single_tile_users value for each date (key)\n",
    "\n",
    "first_var_dict = dict(fb_data.groupby('FB_ds').apply(lambda x: sum(x['FB_all_day_bing_tiles_visited_relative_change'] * x['FB_polygon_name'].map(zone_popn)) / total_popn))\n",
    "second_var_dict = dict(fb_data.groupby('FB_ds').apply(lambda x: sum(x['FB_all_day_ratio_single_tile_users'] * x['FB_polygon_name'].map(zone_popn)) / total_popn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only the date, country, and other relevant columns\n",
    "df = fb_data[['FB_ds', 'FB_country', 'FB_baseline_name', 'FB_baseline_type']].drop_duplicates()\n",
    "\n",
    "# save the population weighted variables to previous (same) column names\n",
    "df['FB_all_day_bing_tiles_visited_relative_change'] = df['FB_ds'].map(first_var_dict)\n",
    "df['FB_all_day_ratio_single_tile_users'] = df['FB_ds'].map(second_var_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outer merge Google data, Oxford data and Facebook data on date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function <i>get_a_or_b</i> which gets either <i>a</i> or <i>b</i>, depending on which value is non-null. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_or_b(row, a, b):\n",
    "    \n",
    "    row = row.fillna('')\n",
    "    \n",
    "    if row[a]:\n",
    "        return row[a]\n",
    "    elif row[b]:\n",
    "        return row[b]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(google_data, oxford_data,  how='outer', left_on=['GCMR_date'], right_on = ['OXCGRT_Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply <i>get_a_or_b</i> to dates and save them in the column, `Date`. It helps to get the non-null column, `Date`, which stores dates. Then, delete the column `GCMR_date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Date'] = merged_df.apply(get_a_or_b, args=('GCMR_date', 'OXCGRT_Date'), axis=1)\n",
    "\n",
    "merged_df.drop(['GCMR_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the step: merging, getting non-null value for date, saving date values in `Date` column, and dropping the redundant date column, `FB_ds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df = pd.merge(merged_df, df,  how='outer', left_on=['Date'], right_on = ['FB_ds'])\n",
    "\n",
    "final_merged_df['Date'] = merged_df.apply(get_a_or_b, args=('Date', 'FB_ds'), axis=1)\n",
    "\n",
    "final_merged_df.drop(['FB_ds'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the final merged dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df.to_csv('Nepal_FB_Google_OXCGRT_{}.csv'.format(int(time.time())), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
